{
 "metadata": {
  "name": "",
  "signature": "sha256:54b520a8527dc422da4298582e599e8e4171d60ff2beae56198478c3972d74b7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sentiment Analysis on Movie Reviews\n",
      "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import precision_score, recall_score, f1_score\n",
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the train data\n",
      "train = pd.read_table(\"train.tsv\")\n",
      "\n",
      "# split into X and y vectors\n",
      "X = train['Phrase']\n",
      "y = train['Sentiment']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because the test data from Kaggle doesn't have resulting sentiment score, we use train_test_split to split the training set into a train and a test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(117045,)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(39015,)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Transform the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit and transform the training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "binary_vectorizer = CountVectorizer(binary=True) # try False - use term frequency rates\n",
      "X_train_v = binary_vectorizer.fit_transform(X_train)\n",
      "print X_train_v.shape\n",
      "print len(binary_vectorizer.vocabulary_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(117045, 15224)\n",
        "15224\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(X_train_v.todense())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "numpy.matrixlib.defmatrix.matrix"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transform the test data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test_v = binary_vectorizer.transform(X_test)\n",
      "X_test_v.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(39015, 15219)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Use Logistic Regression Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Train the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = LogisticRegression()\n",
      "classifier.fit(X_train_v, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(X_train_v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Evaluate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict the y for the test data\n",
      "predictions = classifier.predict(X_test_v)\n",
      "\n",
      "for i in range(10):\n",
      "    print y_test[i], predictions[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 2\n",
        "2 2\n",
        "1 1\n",
        "3 3\n",
        "2 2\n",
        "3 2\n",
        "2 2\n",
        "2 2\n",
        "1 1\n",
        "2 2\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'accuracy', classifier.score(X_test_v, y_test)\n",
      "print 'recall', recall_score(y_test, predictions)\n",
      "print 'precision', precision_score(y_test, predictions)\n",
      "print 'f1', f1_score(y_test, predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy 0.634730231962\n",
        "recall 0.634730231962\n",
        "precision 0.616043750559\n",
        "f1 0.607802213449\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Cross validate the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('vect', CountVectorizer()),\n",
      "    ('clf', LogisticRegression())\n",
      "])\n",
      "\n",
      "parameters = {\n",
      "    'vect__binary': (True, False),\n",
      "}\n",
      "\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=3, scoring='f1')\n",
      "grid_search.fit(X_train, y_train)\n",
      "\n",
      "print 'Best score:', grid_search.best_score_\n",
      "print 'Best parameters set:'\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '\\t', param_name, best_parameters[param_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
        "[CV] vect__binary=True ...............................................\n",
        "[CV] ...................... vect__binary=True, score=0.597916 -   7.2s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[CV] vect__binary=True ...............................................\n",
        "[CV] ...................... vect__binary=True, score=0.599905 -   6.7s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[CV] vect__binary=True ...............................................\n",
        "[CV] ...................... vect__binary=True, score=0.596714 -   7.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[CV] vect__binary=False ..............................................\n",
        "[CV] ..................... vect__binary=False, score=0.597773 -   8.1s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[CV] vect__binary=False ..............................................\n",
        "[CV] ..................... vect__binary=False, score=0.599408 -   9.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[CV] vect__binary=False ..............................................\n",
        "[CV] ..................... vect__binary=False, score=0.595076 -   9.0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    7.2s\n",
        "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   47.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best score:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.59817850257\n",
        "Best parameters set:\n",
        "\tvect__binary True\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_scores = cross_val_score(pipeline, X, y, cv=5)\n",
      "print accuracy_scores, np.mean(accuracy_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.58600032  0.5834241   0.57857807  0.58112784  0.58920218] 0.583666502556\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "precision_scores = cross_val_score(pipeline, X, y, cv=5, scoring='precision')\n",
      "print precision_scores, np.mean(precision_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.55465299  0.54699513  0.54212817  0.54750352  0.55882929] 0.550021820549\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recall_scores = cross_val_score(pipeline, X, y, cv=5, scoring='recall')\n",
      "print recall_scores, np.mean(recall_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.58600032  0.5834241   0.57857807  0.58112784  0.58920218] 0.583666502556\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Evaluate on Kaggle test data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now load the actual test data from Kaggle and test the model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test = pd.read_table(\"test.tsv\")\n",
      "X_actual_test = test['Phrase']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_actual_test = binary_vectorizer.transform(X_actual_test)\n",
      "X_actual_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "(66292, 15227)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict the y for the test data\n",
      "actual_predictions = classifier.predict(X_actual_test)\n",
      "\n",
      "for i in range(10):\n",
      "    print y_test[i], predictions[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 2\n",
        "2 2\n",
        "1 1\n",
        "3 3\n",
        "2 2\n",
        "3 2\n",
        "2 2\n",
        "2 2\n",
        "1 1\n",
        "2 2\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Use K-Nearest Neighbors Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "#classifier2 = KNeighborsClassifier(n_neighbors=30)\n",
      "#classifier2.fit(X_train_v, y_train)\n",
      "#print classifier2.score(X_test_v, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Use Decision Trees"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "pipeline = Pipeline([\n",
      "    ('clf', RandomForestClassifier(criterion='entropy'))\n",
      "])\n",
      "\n",
      "parameters = {\n",
      "    'clf__n_estimators': (5, 10, 20, 50),\n",
      "    'clf__max_depth': (50, 150, 250),\n",
      "    'clf__min_samples_split': (1, 2, 3),\n",
      "    'clf__min_samples_leaf': (1, 2, 3)\n",
      "}\n",
      "\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=3, scoring='f1')\n",
      "grid_search.fit(X_train, y_train)\n",
      "\n",
      "print 'Best score:', grid_search.best_score_\n",
      "print 'Best parameters set:'\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '\\t', param_name, best_parameters[param_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# look into word vector\n",
      "# brown word vector/embedding\n",
      "# hstack to concatenate matrices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}