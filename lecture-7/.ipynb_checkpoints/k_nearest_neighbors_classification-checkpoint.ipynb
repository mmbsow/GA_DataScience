{
 "metadata": {
  "name": "",
  "signature": "sha256:1118b6b13438b88084c8b16f20044818f7d9e54fdabb295129937b5838b3285d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# K-Nearest Neighbors Lab\n",
      "\n",
      "In this lab we will predict the species of flowers in the Iris data set.  \n",
      "You can read about the Iris data set at [http://en.wikipedia.org/wiki/Iris_flower_data_set](http://en.wikipedia.org/wiki/Iris_flower_data_set).  \n",
      "We will assign each test flower to one of three species based on its sepal length and width in centimeters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute this magic command to display figures in-line.\n",
      "%pylab inline\n",
      "# My desktop uses a different back-end.\n",
      "#import matplotlib\n",
      "#matplotlib.use('Qt4Agg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Euclidean Distance\n",
      "\n",
      "Let's get a sense of how Euclidean distance works.  \n",
      "Recall that K-Nearest Neighbors makes local predictions using the `K` training instances that are nearest to the test instance.  \n",
      "Proximity is frequently measured using Euclidean distance in KNN."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.spatial.distance import euclidean\n",
      "a, b = [1, 1], [1, 1]\n",
      "print euclidean(a, b)\n",
      "a, b = [1, 1], [2, 2]\n",
      "print euclidean(a, b)\n",
      "a, b = [1, 1, 1], [2, 2, 222]\n",
      "print euclidean(a, b)\n",
      "# TODO find two points with a distance of 5.\n",
      "# Hint: The points can be in 1-dimensional space\n",
      "\n",
      "# TODO find two points in 2-dimensional space with a distance greater than 10.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating the Classifier\n",
      "Now let's create a KNN classifier with sklearn."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import the `load_iris` convenience function from sklearn.datasets\n",
      "\n",
      "# TODO instantiate the iris data and print the names of the features\n",
      "\n",
      "# For ease of visualization, we are going to work with only the first two features.\n",
      "# TODO slice the data to take all of the rows and the first two columns\n",
      "\n",
      "# TODO how many instances are in the data set?\n",
      "\n",
      "# TODO assign the labels to `y`\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import pyplot as plt\n",
      "\n",
      "# TODO scatter plot the instances. Use a different color for each class.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's train and evaluate a classifier.\n",
      "# TODO import the train_test_split convenience function\n",
      "\n",
      "# TODO create training and test sets\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import the KNeighborsClassifier class from sklearn.neighbors\n",
      "\n",
      "# TODO instantiate a classifier. Set `n_neighbors` (`k`) to 3 and the `metric` to `euclidean`. \n",
      "\n",
      "# TODO fit the classifier\n",
      "\n",
      "# TODO Evaluate the classifier\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Visualizing the Decision Boundaries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's plot the decision boundaries.\n",
      "# This is tricky, so I have saved the process.\n",
      "import numpy as np\n",
      "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
      "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
      "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
      "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
      "Z = Z.reshape(xx.shape)\n",
      "plt.figure()\n",
      "plt.pcolormesh(xx, yy, Z)\n",
      "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
      "plt.xlim(xx.min(), xx.max())\n",
      "plt.ylim(yy.min(), yy.max())\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hyperparameter Tuning through Grid Search\n",
      "\n",
      "Recall that hyperparameters are parameters that are not learned by the learning algorithm. Often, these parameters control how the learning algorithm learns.  \n",
      "`k` is a hyperparameter of KNN. We will find the optimal value of `k` from a set of possible values using grid search.  \n",
      "Grid search is an exhaustive search of hyperparameter space for the values that produce the best model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "hyper_parameters = [{'n_neighbors': [1, 2, 3, 4, 5]}]\n",
      "grid_search = GridSearchCV(KNeighborsClassifier(metric='euclidean'), hyper_parameters, cv=5)\n",
      "grid_search.fit(X_train, y_train)\n",
      "print \"Best parameters set found on development set:\"\n",
      "print grid_search.best_estimator_\n",
      "for params, mean_score, scores in grid_search.grid_scores_:\n",
      "    print mean_score, 'for', params\n",
      "print grid_search.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}