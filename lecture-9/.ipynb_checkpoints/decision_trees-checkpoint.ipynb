{
 "metadata": {
  "name": "decision_trees"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Decision Trees and Random Forests\n",
      "\n",
      "In this lab we will build a binary classifier for use in an ad-blocker. We will predict whether images on a web page are display ads or content.  \n",
      "We will use the Internet Advertisements dataset from [https://archive.ics.uci.edu/ml/datasets/Internet+Advertisements](https://archive.ics.uci.edu/ml/datasets/Internet+Advertisements).  \n",
      "\n",
      "The dataset contains the following explanatory variables:\n",
      "\n",
      "* The height of the image in pixels.\n",
      "* The width of the image in pixels.\n",
      "* The aspect ratio of the image.\n",
      "* Whether or not the image is from the same domain as the web page.\n",
      "* The remainder of the features are from a bag-of-words representation of the URL, alt-text, and caption.\n",
      "\n",
      "The response variable is categorical and takes either the value 'ad' or 'nonad'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import pandas\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exploring the Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO read ad.data into a dataframe. The dataframe does not have a header row.\n",
      "df = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO print the shape of the dataframe\n",
      "\n",
      "# TODO print the dataframe's columns.\n",
      "\n",
      "# TODO print the head of the dataframe. Note that iPython notebook will pretty print by default.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO print the first row of the dataframe.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO describe the data frame.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's check if there are any missing values of the explanatory variables.\n",
      "# TODO we can check for null cells using the `isnull` function.\n",
      "\n",
      "# The dataframe is too large to inspect this way.\n",
      "# TODO instead, we can print the indices of null cells using the following\n",
      "# Are any cells null? Is any cell True along axis 1? Discard the rows for which the previous conditions are not True. Print only the indices.\n",
      "print pd.isnull(df).any(1).nonzero()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that there are no missing values in the dataframe. Let's page through the dataset using `more` to become more familiar with it.  \n",
      "\n",
      "More than one quarter of the instances are missing at least one of the values for the image's dimensions. These missing values are marked by whitespace and a question mark instead of an empty field. pandas parses the question marks as values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO replace \"missing\" values of the explanatory variables with -1.\n",
      "df.replace(to_replace=' *\\?', value=-1, regex=True, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO make a set of the column names\n",
      "\n",
      "# TODO copy the last column describing the response variable from the data frame\n",
      "\n",
      "# TODO remove the last column from the dataframe\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO print the first few values of the response variable\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO encode \"ad.\" as the positive class.\n",
      "y = \n",
      "# TODO what type of object is y?\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO print the first few values of y.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO copy the explanatory variables' columns from the dataframe\n",
      "X = \n",
      "# TODO print the shape of X\n",
      "\n",
      "# TODO print the first few rows of X\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import train_test_split\n",
      "\n",
      "# TODO split the data into training and test sets.\n",
      "# We will further split the training data into training and validation sets for use in grid searching. Why?\n",
      "X_train, X_test, y_train, y_test = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import `DecisionTreeClassifier` from the `tree` module\n",
      "\n",
      "# TODO import `Pipeline` from the `pipeline` module\n",
      "\n",
      "# TODO create a pipeline with one stage, the decision tree classifier. Use the `entropy` `criterion`.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Hyperparameter Tuning with Grid Search"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that *hyperparameters* are parameters of the model that are not learned automatically. Hyperparameters often control how the model learns or is regularized.  \n",
      "sklearn's implementation of decision trees requires several hyperparameters including the maximum depth of the tree and and the minimum numer of instances required to form a leaf."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Specify the hyperparameter space to seach with a dictionary. \n",
      "# The keys are the concatenated name of the keyword argument and the name of the corresponding object.\n",
      "# The values of the dictionary are the values of the hyperparameter that should be tested.\n",
      "parameters = {\n",
      "        'clf__max_depth': (150, 155, 160),\n",
      "        'clf__min_samples_split': (1, 2, 3),\n",
      "        'clf__min_samples_leaf': (1, 2, 3)\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`GridSearchCV` is an estimator. The constructor accepts a `Pipeline` and a parameter space to search.  \n",
      "Grid searching is an *embarrasingly parallel* problem. Multiple models can be fit simultaneously to expedite the search.  \n",
      "The `n_jobs` keyword argument sets the number of processes that Python can fork. Forking requires execution from within a `__main__` protected block."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import `GridSearchCV` from the `grid_search` module\n",
      "\n",
      "# TODO instantiate a GridSearchCV\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=1, verbose=3, scoring='f1')\n",
      "# TODO fit grid_search. What is happening here? How many models will be trained?\n",
      "\n",
      "print 'Best score:', grid_search.best_score_\n",
      "print 'Best parameters set:'\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '\\t', param_name, best_parameters[param_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, the `GridSearchCV` object will be re-fit using the best values of the hyperparameters.  \n",
      "Predictions can then be made using the object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import `classification_report` from the `metrics` module.\n",
      "\n",
      "# TODO make predictions for the test set using the `grid_search` object.\n",
      "\n",
      "# TODO `grid_search` also implements a `score` method.\n",
      "\n",
      "# TODO print the classification report for the predictions.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Random Forests\n",
      "\n",
      "Now let's replace the decision tree with a random forest."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO import `RandomForestClassifier` from the `ensemble` module.\n",
      "\n",
      "# TODO create a new pipeline with a `RandomForestClassifier`\n",
      "pipeline = \n",
      "# TODO we will add another hyperparameter specific to random forests to our grid search. How will this affect the number of models that are fit?\n",
      "parameters = {\n",
      "    'clf__n_estimators': (5, 10, 20, 50),\n",
      "    'clf__max_depth': (50, 150, 250),\n",
      "    'clf__min_samples_split': (1, 2, 3),\n",
      "    'clf__min_samples_leaf': (1, 2, 3)\n",
      "}\n",
      "# TODO create a new `GridSearchCV`\n",
      "\n",
      "# TODO traing the grid_search\n",
      "\n",
      "print 'Best score:', grid_search.best_score_\n",
      "print 'Best parameters set:'\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print '\\t', param_name, best_parameters[param_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}